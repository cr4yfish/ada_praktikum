{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbgYWScQSQ4-"
      },
      "source": [
        "Dieses Notebook zeigt, wie man ein spezielles Rekurrentes Neuronales Netz (LSTM) zur Vorhersage von Energieverbrauchsdaten trainieren kann. \n",
        "HierfÃ¼r werden die Bibliotheken keras, sowie sci-kit learn verwendet.\n",
        "Das Notebook orientiert sich an folgendem Tutorial: https://www.elab2go.de/demo-py5/ (Autoren: Prof. Dr. Eva Maria Kiss, B. Sc. Franc Willy Pouhela, M. Sc. Anke Welz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\manue\\anaconda3\\lib\\site-packages (1.24.3)\n",
            "Requirement already satisfied: pandas in c:\\users\\manue\\anaconda3\\lib\\site-packages (1.5.3)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\manue\\anaconda3\\lib\\site-packages (3.7.1)\n",
            "Requirement already satisfied: seaborn in c:\\users\\manue\\anaconda3\\lib\\site-packages (0.12.2)\n",
            "Requirement already satisfied: sklearn in c:\\users\\manue\\anaconda3\\lib\\site-packages (0.0.post10)\n",
            "Requirement already satisfied: tensorflow in c:\\users\\manue\\anaconda3\\lib\\site-packages (2.14.0)\n",
            "Requirement already satisfied: keras in c:\\users\\manue\\anaconda3\\lib\\site-packages (2.14.0)\n",
            "Requirement already satisfied: graphviz in c:\\users\\manue\\anaconda3\\lib\\site-packages (0.20.1)\n",
            "Requirement already satisfied: pydot in c:\\users\\manue\\anaconda3\\lib\\site-packages (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow) (2.14.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.24.4)\n",
            "Requirement already satisfied: setuptools in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.0)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# install deps\n",
        "%pip install numpy pandas matplotlib seaborn sklearn tensorflow keras graphviz pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XKCtHqefSPFj"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32ms:\\Dateien\\localProjects\\ada_praktikum\\manuel\\HandsOnPython_06_NeuronalesNetz.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Dateien/localProjects/ada_praktikum/manuel/HandsOnPython_06_NeuronalesNetz.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m max_error\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Dateien/localProjects/ada_praktikum/manuel/HandsOnPython_06_NeuronalesNetz.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# keras fÃ¼r Neuronale Netze\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/Dateien/localProjects/ada_praktikum/manuel/HandsOnPython_06_NeuronalesNetz.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m \n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Dateien/localProjects/ada_praktikum/manuel/HandsOnPython_06_NeuronalesNetz.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/Dateien/localProjects/ada_praktikum/manuel/HandsOnPython_06_NeuronalesNetz.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential \n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     41\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\__init__.py:43\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[39m# from tensorflow.python import keras\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m# from tensorflow.python.layers import layers\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m saved_model\n\u001b[1;32m---> 43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m \u001b[39mimport\u001b[39;00m api\n\u001b[0;32m     45\u001b[0m \u001b[39m# Sub-package for performing i/o directly instead of via ops in a graph.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m python_io\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\tpu\\api.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m \u001b[39mimport\u001b[39;00m bfloat16\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_column_v2\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m \u001b[39mimport\u001b[39;00m tpu\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtpu\u001b[39;00m \u001b[39mimport\u001b[39;00m tpu_embedding\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\tpu\\feature_column_v2.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39menum\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_column \u001b[39mas\u001b[39;00m fc\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_column_lib \u001b[39mas\u001b[39;00m fc_lib\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:143\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_tensor \u001b[39mas\u001b[39;00m sparse_tensor_lib\n\u001b[0;32m    142\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n\u001b[1;32m--> 143\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[0;32m    144\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n\u001b[0;32m    145\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops_stack\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\layers\\base.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# =============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy_tf_layers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[0;32m     18\u001b[0m InputSpec \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mInputSpec\n\u001b[0;32m     20\u001b[0m keras_style_scope \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mkeras_style_scope\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\keras\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\keras\\models.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics \u001b[39mas\u001b[39;00m metrics_module\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v1\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m functional\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m sequential\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_spec\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[1;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training \u001b[39mas\u001b[39;00m training_lib\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training_utils\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m network_serialization\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:54\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m loss_scale_optimizer \u001b[39mas\u001b[39;00m lso\n\u001b[0;32m     53\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m policy\n\u001b[1;32m---> 54\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m hdf5_format\n\u001b[0;32m     55\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m save\n\u001b[0;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m saving_utils\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py:37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 37\u001b[0m   \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[0;32m     38\u001b[0m   HDF5_OBJECT_HEADER_LIMIT \u001b[39m=\u001b[39m \u001b[39m64512\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\manue\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:59\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m h5a, h5d, h5ds, h5f, h5fd, h5g, h5r, h5s, h5t, h5p, h5z, h5pl\n\u001b[0;32m     58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_hl\u001b[39;00m \u001b[39mimport\u001b[39;00m filters\n\u001b[1;32m---> 59\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_hl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m is_hdf5, HLObject, Empty\n\u001b[0;32m     60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_hl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfiles\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     61\u001b[0m     File,\n\u001b[0;32m     62\u001b[0m     register_driver,\n\u001b[0;32m     63\u001b[0m     unregister_driver,\n\u001b[0;32m     64\u001b[0m     registered_drivers,\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_hl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroup\u001b[39;00m \u001b[39mimport\u001b[39;00m Group, SoftLink, ExternalLink, HardLink\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:1032\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:1130\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import math\n",
        "\n",
        "# matplotlib und seaborn zum Plotten\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# scikit-learn fÃ¼r Ãberwachtes Lernen\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import max_error\n",
        "\n",
        "# keras fÃ¼r Neuronale Netze\n",
        "import tensorflow as tf \n",
        "import keras as keras\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, LSTM, Dropout \n",
        "from keras.utils.vis_utils import plot_model \n",
        "from keras import activations\n",
        "\n",
        "# FÃ¼r das Darstellen von Bildern im SVG-Format\n",
        "import graphviz as gv\n",
        "import pydot\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmm976BpAi1i"
      },
      "outputs": [],
      "source": [
        "# Daten einlesen\n",
        "data = pd.read_csv('https://www.elab2go.de/demo-py5/opsd_2016-2019.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXwyyg9jCTtF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Datum</th>\n",
              "      <th>Verbrauch</th>\n",
              "      <th>Wind</th>\n",
              "      <th>Solar</th>\n",
              "      <th>Wind+Solar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>1007.11</td>\n",
              "      <td>107.21</td>\n",
              "      <td>18.56</td>\n",
              "      <td>125.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>1147.89</td>\n",
              "      <td>409.62</td>\n",
              "      <td>9.40</td>\n",
              "      <td>419.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>1130.63</td>\n",
              "      <td>406.30</td>\n",
              "      <td>13.52</td>\n",
              "      <td>419.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>1385.93</td>\n",
              "      <td>278.46</td>\n",
              "      <td>10.08</td>\n",
              "      <td>288.54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>1430.11</td>\n",
              "      <td>206.47</td>\n",
              "      <td>12.55</td>\n",
              "      <td>219.02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Datum  Verbrauch    Wind  Solar  Wind+Solar\n",
              "0  2016-01-01    1007.11  107.21  18.56      125.77\n",
              "1  2016-01-02    1147.89  409.62   9.40      419.02\n",
              "2  2016-01-03    1130.63  406.30  13.52      419.82\n",
              "3  2016-01-04    1385.93  278.46  10.08      288.54\n",
              "4  2016-01-05    1430.11  206.47  12.55      219.02"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtUkldNHCU7B"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Datum</th>\n",
              "      <th>Verbrauch</th>\n",
              "      <th>Wind</th>\n",
              "      <th>Solar</th>\n",
              "      <th>Wind+Solar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>2019-12-27</td>\n",
              "      <td>1172.20</td>\n",
              "      <td>146.59</td>\n",
              "      <td>20.96</td>\n",
              "      <td>167.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>2019-12-28</td>\n",
              "      <td>1141.33</td>\n",
              "      <td>159.13</td>\n",
              "      <td>36.24</td>\n",
              "      <td>195.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>2019-12-29</td>\n",
              "      <td>1087.07</td>\n",
              "      <td>349.84</td>\n",
              "      <td>54.91</td>\n",
              "      <td>404.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>2019-12-30</td>\n",
              "      <td>1200.05</td>\n",
              "      <td>669.27</td>\n",
              "      <td>53.22</td>\n",
              "      <td>722.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1460</th>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>1124.93</td>\n",
              "      <td>425.22</td>\n",
              "      <td>36.56</td>\n",
              "      <td>461.79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Datum  Verbrauch    Wind  Solar  Wind+Solar\n",
              "1456  2019-12-27    1172.20  146.59  20.96      167.55\n",
              "1457  2019-12-28    1141.33  159.13  36.24      195.36\n",
              "1458  2019-12-29    1087.07  349.84  54.91      404.75\n",
              "1459  2019-12-30    1200.05  669.27  53.22      722.49\n",
              "1460  2019-12-31    1124.93  425.22  36.56      461.79"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ruAL4TjMF-m"
      },
      "source": [
        "# Aufgabe 1: Datenvorbereitung\n",
        " \n",
        "\n",
        "* a) ÃberprÃ¼fen Sie, ob in dem Datensatz NaN enthalten sind. Falls ja, Ã¼berlegen Sie sich, wie Sie damit am besten umgehen.\n",
        "*   b) Ist es sinnvoll, mit allen Merkmalen fortzufahren? Was mÃ¼ssen Sie tun um diese Frage beantworten zu kÃ¶nnen?\n",
        "*   c) Bringen Sie die Spalte \"Datum\" in ein geeignetes Format und indizieren Sie das dataframe mit dieser Spalte \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LprFtFGuCYQL"
      },
      "outputs": [],
      "source": [
        "# Frage 1 a) ÃberprÃ¼fen auf NaN\n",
        "\n",
        "# ....."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCrYJQHBNT2Y"
      },
      "outputs": [],
      "source": [
        "# Frage 1 b)\n",
        "\n",
        "# .....\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9IjK4isNOi6"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYYRMjO6C6dY"
      },
      "outputs": [],
      "source": [
        "# Frage 1 c)\n",
        "\n",
        "# ....."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhkcjBBsCsT1"
      },
      "outputs": [],
      "source": [
        "# Plotten des Stromverbrauchs. Der Stromverbrauch soll spÃ¤ter mithilfe des Neuronalen Netzes vorhergesagt werden.\n",
        "\n",
        "sns.set(rc={'figure.figsize':(12, 4)})\n",
        "sns.set_color_codes('bright')\n",
        "\n",
        "ax = data['Verbrauch'].plot(linewidth=1, color='b', marker = '.')\n",
        "ax.set_title('TÃ¤glicher Stromverbrauch')\n",
        "ax.set_xlabel('Datum');\n",
        "ax.set_ylabel('GwH');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-y0FKomOETF"
      },
      "source": [
        "# Aufgabe 2\n",
        "\n",
        "Im nÃ¤chsten Codeblock werden zeitlich versetzte Merkmale (sogenannte Lagged Features) erzeugt.  \n",
        "\n",
        "*   a) Was macht dabei die Funktion shift()? Schauen Sie in der pandas Dokumentation nach!\n",
        "*   b) Was macht die Funktion concat()? Schauen Sie auch das in der pandas Dokumentation nach!\n",
        "*   c) FÃ¼hren Sie die untenstehende Zelle aus und Lassen Sie sich anschlieÃend die ersten 10 Zeilen des neu erzeugten dataframes ausgeben. Hat das Erzeugen der zeitlich versetzten Merkmale erfolgreich funktioniert?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXixVLD8UU6I"
      },
      "source": [
        "# Antworten\n",
        "\n",
        "\n",
        "\n",
        "*   a) ....\n",
        "*   b) ....\n",
        "*   c) .....\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38nuB_e8Fgyd"
      },
      "outputs": [],
      "source": [
        "# Erzeuge zeitlich versetzte Merkmale (lagged features)\n",
        "\n",
        "consumption = pd.DataFrame(data['Verbrauch'])\n",
        "\n",
        "data = pd.concat([consumption.shift(7),consumption.shift(6), consumption.shift(5), consumption.shift(4), \n",
        "                  consumption.shift(3), consumption.shift(2), consumption.shift(1), data[['Verbrauch']]], axis=1)\n",
        "\n",
        "data.columns =  ['t-7', 't-6', 't-5', 't-4', 't-3', 't-2', 't-1', 'Verbrauch']\n",
        "\n",
        "data.head()\n",
        "\n",
        "data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnvY2JYtTNXn"
      },
      "outputs": [],
      "source": [
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cITs1ZxLCzXQ"
      },
      "outputs": [],
      "source": [
        "# Daten in Trainings- und Testset aufspalten\n",
        "\n",
        "TEST_SPLIT = 0.1 \n",
        "#data = data.drop(columns = ['Wind', 'Solar'])\n",
        "train_size = int(len(data) * (1-test_split))\n",
        "test_size = len(data) - train_size\n",
        "train = data.iloc[0:train_size]\n",
        "test = data.iloc[train_size:len(data)]\n",
        "print(\"Trainingsdaten:\") \n",
        "print(train.head())\n",
        "print(train.tail())\n",
        "print(\"Testdaten:\") \n",
        "print(test.head())\n",
        "print(test.tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLkdRtBBDOOE"
      },
      "outputs": [],
      "source": [
        "# Daten auf den Wertebereich [0, 1] skalieren\n",
        "\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "\n",
        "train_s = scaler.fit_transform(np.array(train))\n",
        "test_s = scaler.fit_transform(np.array(test))\n",
        "\n",
        "print(\"Trainingsdaten (unskaliert)\\n\")\n",
        "print(train.head(3))\n",
        "print(\"\\nTrainingsdaten (skaliert)\\n\")\n",
        "train_s = pd.DataFrame( train_s , columns = data.columns)\n",
        "train_s = train_s.set_index(train.index )\n",
        "print(train_s.head(3))\n",
        "\n",
        "print(\"Testdaten (unskaliert)\\n\")\n",
        "print(test.head(3))\n",
        "print(\"\\nTestdaten (skaliert)\\n\")\n",
        "test_s = pd.DataFrame( test_s , columns = data.columns)\n",
        "test_s = test_s.set_index(test.index )\n",
        "print(test_s.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjYQ-fbzUvdu"
      },
      "outputs": [],
      "source": [
        "# In Merkmale und Label aufteilen\n",
        "\n",
        "X_train = train_s.drop(columns = ['Verbrauch'])\n",
        "y_train = pd.DataFrame(train_s['Verbrauch'])\n",
        "\n",
        "print(X_train.head())\n",
        "print(y_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBpV9MC4EBSK"
      },
      "outputs": [],
      "source": [
        "TIMESTEPS = 7 # LÃ¤nge eines gleitenden Zeitfensters\n",
        "UNITS = 10 # Ausgabedimension einer einzelnen LSTM-Schicht\n",
        "N_LAYER = 2 # Anzahl an LSTM-Schichten\n",
        "\n",
        "# Initialisiere ein sequentielles Modell (Modell mit mehreren Schichten)\n",
        "model = Sequential(name='sequential') \n",
        "\n",
        "#FÃ¼ge so viele Schichten hinzu, wie in N_LAYER angegeben\n",
        "for i in range(N_LAYER):\n",
        "\n",
        "  lstm_layer = LSTM(units = UNITS, # Dimension der Ausgabe\n",
        "                    input_shape=(TIMESTEPS,1), # Dimension der Eingabe (1. Dimension entspricht Anzahl Zeitschritte, 2. Dimension:  1, da nur ein Merkmal = Verbrauch Ã¼ber die Zeit betrachtet wird (univariates Problem) )\n",
        "                    return_sequences=True, # wir wollen die gesamte Ausgabesequenz der jeweiligen LSTM-Schicht in die nÃ¤chste LSTM-Schicht weitergeben kÃ¶nnen\n",
        "                    name = 'lstm_' + str(i+1)) # Schichten werden mit \"lstm_\" + Schichtnummer benannt\n",
        "                   \n",
        "  model.add(lstm_layer) # Schicht dem Modell hinzufÃ¼gen\n",
        "\n",
        "\n",
        "# weitere LSTM Schicht hinzufÃ¼gen, bei der nur die letzte Ausgabe (und nicht wie oben die ganze Sequenz) in die nÃ¤chste Schicht weitergegeben wird\n",
        "model.add(LSTM(units = UNITS, input_shape=(TIMESTEPS,1), name = 'lstm_' + str(N_LAYER+1)))\n",
        "\n",
        "# Lineares Layer mit ReLU-Aktivierungsfunktion\n",
        "model.add(Dense(units = 1, name='dense_1'))#, activation=activations.tanh))\n",
        "\n",
        "# Konfiguriere das Modell fÃ¼r die Trainingsphase \n",
        "\n",
        "# Angeben welcher Optimierer verwendet werden soll\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Ã¼ber welche Verlustfunktion optimiert werden soll \n",
        "# und wie die Performance des Modells gemessen werden soll (hier werden Verlustfunktion und Performancemetrik gleich gewÃ¤hlt, muss aber nicht so sein))\n",
        "model.compile(optimizer = opt, loss = \"mse\", metrics=['mean_squared_error'])\n",
        "\n",
        "# Zusammenfassung und Visualisierung des Modells\n",
        "model.summary()\n",
        "plot_model(model, show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrKru1jmRN3G"
      },
      "source": [
        "# Aufgabe 3\n",
        "\n",
        "Welchen Parameter der obigen Codezelle mÃ¼ssten Sie verÃ¤ndern, um 3 LSTM Schichten zu bekommen?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRrNMG51SAEt"
      },
      "source": [
        "# Aufgabe 4\n",
        "\n",
        "Das Neuronale Netz wird in der unten stehenden Codezelle trainiert. FÃ¼hren Sie den Code aus. \n",
        "Nach wie vielen Epochen wird das Training auf jeden Fall stoppen?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fk5LqeA9EFMd"
      },
      "outputs": [],
      "source": [
        "# Modell trainieren\n",
        "\n",
        "# Erstelle Callback fÃ¼r Stop-Kriterium\n",
        "from keras.callbacks import EarlyStopping, CSVLogger\n",
        "cb_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
        "                        verbose=1, patience=200)\n",
        "log_file = 'demo-py5-log.csv'\n",
        "cb_logger = CSVLogger(log_file, append=False, separator=';')\n",
        "\n",
        "# X_train erhÃ¤lt eine zusÃ¤tzliche Dimension und wird dreidimensional\n",
        "X_train = np.array(X_train)\n",
        "X_train = np.reshape(X_train, \n",
        "                     (X_train.shape[0], X_train.shape[1], 1))\n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "# Trainiere das Modell mit Hilfe der Funktion fit()\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 1000\n",
        "history = model.fit(X_train, y_train, \n",
        "                    epochs=EPOCHS, batch_size=BATCH_SIZE, \n",
        "                    validation_split=TEST_SPLIT, verbose=2, \n",
        "                    callbacks=[cb_logger, cb_stop])\n",
        "\n",
        "# Speichere das Modell im Format HDF5\n",
        "model.save(\"model_adam.h5\")\n",
        "\n",
        "print(\"History\");print(history.history.keys());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQA7oBZ6TP6X"
      },
      "source": [
        "# Aufgabe 5\n",
        "\n",
        "Im untenstehenden Codeblock wird der Trainingsfortschritt geplottet. Wie beurteilen Sie ihn?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96-yfi5QmDBC"
      },
      "outputs": [],
      "source": [
        "# Trainingsfortschritt plotten\n",
        "\n",
        "plt.plot(history.history['mean_squared_error'], label='MSE (Trainingsdaten)')\n",
        "plt.plot(history.history['val_mean_squared_error'], label='MSE (Testdaten)')\n",
        "\n",
        "plt.title('Training: Entwicklung des Fehlers')\n",
        "plt.ylabel('MSE-Fehler')\n",
        "plt.xlabel('Epochen')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl7Kw0kEmNsE"
      },
      "outputs": [],
      "source": [
        "# Testdaten in Merkmale X und Label y aufteilen\n",
        "\n",
        "X_test = test_s.drop(columns = ['Verbrauch'])\n",
        "y_test = pd.DataFrame(test_s['Verbrauch'])\n",
        "\n",
        "# Vorhersage fÃ¼r skalierte Testdaten\n",
        "X_test = np.array(X_test)\n",
        "X_test_input = np.reshape(X_test, \n",
        "        (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "#y_test = np.reshape(y_test, \n",
        "        # (y_test.shape[0],  1))\n",
        "y_pred = model.predict(X_test_input)\n",
        "\n",
        "pred = np.concatenate((X_test, y_pred), axis=1)\n",
        "\n",
        "# Reskaliere die Daten\n",
        "test_rs = pd.DataFrame(scaler.inverse_transform(test_s), columns = test_s.columns)\n",
        "pred_rs = pd.DataFrame(scaler.inverse_transform(pred), columns = test_s.columns)\n",
        "\n",
        "y_test = test_rs['Verbrauch']\n",
        "y_pred = pred_rs['Verbrauch']\n",
        "\n",
        "# Berechne RMSE der Validierungsdaten\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.round(np.sqrt(mse))\n",
        "print(\"Validierungs-Fehler:\")\n",
        "print(\"\\nMSE:\\n %.2lf\" % (mse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axF8FLI5qxkt"
      },
      "outputs": [],
      "source": [
        "def rel_error(df, col1, col2):\n",
        "    df['Error (%)'] = (df[col1] - df[col2]) / df[col1]  * 100\n",
        "    df['Error (%)'] = df['Error (%)'].abs()\n",
        "    return df['Error (%)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HN0q4AodxpPj"
      },
      "outputs": [],
      "source": [
        "# Hilfsfunktion error_table erzeugt Fehlertabelle\n",
        "def error_table(df1, df2, col1, col2, idx):\n",
        "    cols = [df1, df2]\n",
        "    headers = [col1, col2]\n",
        "    # Erzeuge pred aus y_test und y_pred mit Index idx\n",
        "    pred = pd.concat(cols, axis=1, keys=headers) \n",
        "    pred.set_index(idx, inplace=True)\n",
        "    # FÃ¼ge Fehler-Spalten hinzu\n",
        "    pred['Error'] = np.abs(pred['y_test'] - pred['y_pred'])\n",
        "    pred['Error(%)'] = rel_error(pred, 'y_test', 'y_pred')\n",
        "    pred = pred.astype(float).round(1)\n",
        "    # FÃ¼ge RMSE hinzu\n",
        "    mse = mean_squared_error(df1, df2)\n",
        "    rmse = np.round(np.sqrt(mse))\n",
        "    pred.index.name = \"RMSE: \" + str(rmse)\n",
        "    return pred\n",
        "\n",
        "# Erzeuge Fehlertabelle fÃ¼r Validierung und gebe sie aus\n",
        "idx = test.index;\n",
        "pred = error_table(pd.DataFrame(y_test), pd.DataFrame(y_pred), 'y_test', 'y_pred', idx)\n",
        "\n",
        "pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf8vmdiCmWPg"
      },
      "outputs": [],
      "source": [
        "pred['Error (%)'].min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBvPJvxdmZ9N"
      },
      "outputs": [],
      "source": [
        "pred['Error (%)'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTPeFBiX-bga"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_ruAL4TjMF-m",
        "KrKru1jmRN3G"
      ],
      "name": "HandsOnPython_06_NeuronalesNetz.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
